## üìò Resumo: Processamento em Paralelo

## üß† 1. Computa√ß√£o de Alto Desempenho por Meio do Processamento em Paralelo

### Evolu√ß√£o dos Computadores
- Aumento de desempenho e capacidade com redu√ß√£o de custos.
- Exemplos: smartphones, tablets, notebooks com capacidade superior a mainframes dos anos 60/70.
- Aplica√ß√µes que demandam alto processamento:
  - Processamento de imagem
  - Reconhecimento de linguagem
  - Videoconfer√™ncia
  - Renderiza√ß√£o 3D
  - Modelagem e simula√ß√£o

### Paralelismo em N√≠vel de Instru√ß√µes
- **Pipeline**: Divis√£o da execu√ß√£o de instru√ß√µes em est√°gios discretos. V√°rias instru√ß√µes s√£o executadas simultaneamente em est√°gios diferentes.
- **Superscalar**: M√∫ltiplas instru√ß√µes independentes s√£o executadas ao mesmo tempo em unidades funcionais diferentes.
- **VLIW (Very Long Instruction Word)**: Compilador define quais instru√ß√µes executar em paralelo.
- **Hyper-Threading (Intel)**: Cria dois processadores virtuais a partir de um f√≠sico, simulando multiprocessamento.

### Processadores Vetoriais e Matriciais
- **Vetoriais**: Executam a mesma opera√ß√£o em m√∫ltiplos dados (SIMD).
- **Matriciais (MPP)**: M√∫ltiplas unidades de processamento executam a mesma instru√ß√£o em paralelo (massivamente paralelos).

### Superpipeline vs. Superscalar
- **Superpipeline**: Est√°gios do pipeline executam tarefas em menos de meio ciclo de clock, permitindo clock interno mais r√°pido.
- **Superscalar**: M√∫ltiplas unidades de execu√ß√£o em paralelo.

---

## ‚öôÔ∏è 2. Tipos de Organiza√ß√µes de Processadores Paralelos

### Taxonomia de Flynn (1966)
Classifica√ß√£o baseada em fluxos de instru√ß√µes e dados:

| | Fluxo √önico de Instru√ß√µes | Fluxo M√∫ltiplo de Instru√ß√µes |
|---|---|---|
| **Fluxo √önico de Dados** | SISD (Von Neumann) | MISD (Te√≥rico) |
| **Fluxo M√∫ltiplo de Dados** | SIMD (Vetorial/Matricial) | MIMD (Multiprocessadores) |

- **SISD**: Computador sequencial tradicional.
- **SIMD**: Uma instru√ß√£o opera sobre m√∫ltiplos dados (ex.: GPUs).
- **MIMD**: M√∫ltiplos processadores independentes (ex.: clusters, SMP).

### Multiprocessadores Sim√©tricos (SMP)
- Dois ou mais processadores similares.
- Compartilham mem√≥ria principal e dispositivos de E/S.
- Controlados por um √∫nico SO.
- Vantagem: Balanceamento de carga e escalabilidade.

### Esquemas de Interconex√£o
- Barramentos compartilhados
- Redes de interconex√£o
- Coer√™ncia de cache: Protocolos para manter consist√™ncia entre caches (ex.: escuta de barramento).

### Arquiteturas de Acesso √† Mem√≥ria
- **UMA (Uniform Memory Access)**: Acesso uniforme √† mem√≥ria via barramento compartilhado.
- **NUMA (Non-Uniform Memory Access)**: Acesso √† mem√≥ria varia conforme a localiza√ß√£o (mais r√°pido se local).
- **CC-NUMA (Cache Coherent NUMA)**: Mant√©m coer√™ncia de cache em sistemas NUMA.

---

## üîß 3. Desempenho do Hardware e Computadores Multicore

### Limita√ß√µes do Aumento de Clock
- Consumo de energia e gera√ß√£o de calor.
- Complexidade e custo de desenvolvimento.
- **Regra de Pollack**: Desempenho ‚àù ‚àö(complexidade). Dobrar a complexidade resulta em ~40% de ganho.

### Solu√ß√£o: Arquiteturas Multicore
- M√∫ltiplos n√∫cleos (cores) em um √∫nico chip.
- Cada core tem componentes independentes (ULA, UC, cache L1).
- Compartilham cache L2/L3 e controladores de mem√≥ria.

### Vantagens dos Multicore
- Melhor desempenho por watt.
- Maior efici√™ncia energ√©tica.
- Potencial de escalabilidade quase linear (se software for paraleliz√°vel).

### Organiza√ß√£o de Cache em Multicore
- **Cache L1 dedicada** por core.
- **Cache L2 dedicada ou compartilhada**.
- **Cache L3 compartilhada** (ex.: Intel Core i7).

### Multithreading Simult√¢neo (SMT / Hyper-Threading)
- Um core f√≠sico executa m√∫ltiplas threads simultaneamente.
- Aumenta a utiliza√ß√£o dos recursos do core.
- Exemplo: Intel Core i7 com Hyper-Threading.

### Desempenho do Software em Multicore
- Aplica√ß√µes devem ser paraleliz√°veis para aproveitar m√∫ltiplos cores.
- Exemplos:
  - Aplica√ß√µes multithread (n√≠vel de thread)
  - M√∫ltiplos processos (n√≠vel de processo)
  - M√∫ltiplas inst√¢ncias de aplica√ß√£o (n√≠vel de aplica√ß√£o)

---

## ‚úÖ 4. Pontos-Chave

- **Pipeline**: Reduz tempo de execu√ß√£o com est√°gios sobrepostos.
- **Superscalar**: Executa m√∫ltiplas instru√ß√µes por ciclo.
- **Taxonomia de Flynn**: SISD, SIMD, MIMD, MISD.
- **SMP**: Multiprocessadores sim√©tricos com mem√≥ria compartilhada.
- **UMA vs NUMA**: Acesso uniforme vs. n√£o uniforme √† mem√≥ria.
- **Multicore**: M√∫ltiplos n√∫cleos em um chip, com caches compartilhadas.
- **SMT/Hyper-Threading**: Execu√ß√£o simult√¢nea de threads em um core.
- **Regra de Pollack**: Limita√ß√£o do ganho de desempenho com aumento de complexidade.

---

## üìö 5. Refer√™ncias Sugeridas

- Stallings, W. ‚Äì *Arquitetura e Organiza√ß√£o de Computadores*
- Tanenbaum, A. ‚Äì *Sistemas Distribu√≠dos*
- Monteiro, M. ‚Äì *Introdu√ß√£o √† Organiza√ß√£o de Computadores*

---
